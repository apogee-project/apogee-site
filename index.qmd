---
title: "Apogee"
subtitle: "AI/ML-Powered Grant Evaluation, Education, and Efficiency Ecosystem"
---

## 1. Executive Summary

This proposal outlines the development and implementation of an AI/ML-powered system to enhance the evaluation of NIH grant proposals before submission. This system aims to provide quantitative measures of impact, alignment with funding opportunity announcements (RFAs), and overall grant quality. By leveraging advanced natural language processing (NLP) and machine learning techniques, we can offer researchers valuable insights, improve grant applications, and ultimately increase success rates in securing NIH funding. The system will analyze proposal documents, compare them against existing successful grants, and provide actionable feedback to strengthen applications.

## 2. Mission Statement

To empower researchers with AI-driven tools that provide comprehensive, objective, and timely feedback on NIH grant proposals, maximizing their potential for funding success and advancing scientific discovery.

SEE the [formal proposal](./strategic-plan.md)

## 3. Metrics of Interest

- **Readability Scores:** Assess the clarity and accessibility of the proposal's language. (Flesch-Kincaid, etc.)
- **Similarity Metrics:** Compare the proposal to previously funded grants (IC, study section, grant type).
- **Alignment with RFA:** Measure how well the proposal addresses the specific goals and requirements of the RFA.
- **Quantitative Impact Measures:** Identify and quantify the potential impact of the proposed research.
- **Keyword Analysis:** Extract and analyze key terms to ensure alignment with current research trends and NIH priorities.
- **SMART Metrics:** Evaluate the Specificity, Measurability, Achievability, Relevance, and Time-bound nature of the proposed aims.

## 4. Evaluation Approaches

- **Natural Language Processing (NLP):** Analyze the text of the proposal to identify key concepts, research aims, and methodologies.
- **Machine Learning (ML):** Train models on a dataset of funded and unfunded proposals to predict the likelihood of funding success.
- **Similarity Analysis:** Compare the proposal to a database of existing grants to identify similarities and differences.
- **Multiaxial Evaluation:** Implement a system that evaluates proposals across multiple dimensions (e.g., scientific merit, innovation, feasibility).
- **LLM Integration:** Use Large Language Models (LLMs) to generate narrative summaries, identify strengths and weaknesses, and provide suggestions for improvement.

## 5. Infrastructure

- **SSO/MFA:** Secure access to the system.
- **LLM APIs:** Integrate with OpenAI, Azure Open models, and explore local/open-source LLMs.
- **GPU:** Utilize GPUs for efficient processing of LLM tasks.
- **Storage:** Robust storage solutions for grant documents, analysis results, and model data.
- **Web Server:** A web interface for users to upload and analyze proposals.
- **Data Engineering Pipeline:** Automated pipeline for data ingestion, processing, and analysis.
- **Security Scanning:** Regular security checks to protect sensitive data.
- **Database:** A database to store grant information, evaluation metrics, and analysis results.

## 6. Minimum Viable Product (MVP)

- **Inputs:**
  - Specific aims page (+/- previous summary statement)
  - RFA PDF
- **Outputs:**
  - LLM-generated narrative summary
  - Readability scores
  - Similarity scores to other grants
  - Suggested study sections (+/-)
  - Keywords
  - SMART metrics (or similar)

## 7. Available Resources

- **Data:** PubMed, PMC, Grants Reporter, Citation data, iCite, Patents, Clinical trials, CCTSI grants and summary statements.
- **Personnel:** CCTSI (Tom Yaeger, Melanie), Ophthalmology data scientists, Software engineering team (frontend, backend, data engineering, R).

## 8. Funding

- **CCTSI**
- **CC**
- **Dean Sampson (?)**
- **Anticipated Costs:**
  - Personnel ($10,000)
  - API/LLM costs ($2,000)
  - IT personnel ($XXXXX)

## 9. Ideas

- OGC grant opt-in for AI evaluation
- Grant writing tool to assess grants dynamically

## 10. Next Steps

- Further define the MVP and develop a detailed project plan.
- Secure necessary funding and resources.
- Develop and train the AI/ML models.
- Build the web interface and data pipeline.
- Pilot test the system with a small group of researchers.
- Gather feedback and iterate on the system.

